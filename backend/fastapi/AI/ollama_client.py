# backend/AI/ollama_client.py
# Functions to interact with the Ollama API

# Example:
# import httpx

# async def classify_with_ollama(text: str):
#     async with httpx.AsyncClient() as client:
#         response = await client.post("http://localhost:11434/api/generate", json={...})
#         # Process response
#         return ...
